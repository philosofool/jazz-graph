{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import Counter\n",
    "import jsonlines\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.typing import ArrayLike\n",
    "import os\n",
    "\n",
    "from ignite.engine import Engine, Events\n",
    "from ignite.metrics import Recall, Precision, Accuracy, Loss\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "from torch_geometric.nn import GraphConv, SAGEConv, to_hetero, HeteroConv\n",
    "from torch_geometric import transforms as T\n",
    "from torch_geometric import seed_everything\n",
    "\n",
    "from jazz_graph.data.utils import inspect_degrees\n",
    "from jazz_graph.logging import JSONRunLogger, run_evaluator, log_experiment, binary_output_transform\n",
    "from jazz_graph.pyg_data.pyg_data import CreateTensors\n",
    "from jazz_graph.model import JazzModel, LinkPredictionModel, NodeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = '/workspace/local_data/graph_parquet_proto'\n",
    "create = CreateTensors(models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: report on the data a little more concreately.\n",
    "# E.g., who are the hub nodes? How many nodes have > 50 edges.\n",
    "# how many nodes have < 6 edges? All these, by type.\n",
    "# Get really fancy and visualize a sub-graph.\n",
    "\n",
    "def frequency_of_n_labels(data: HeteroData):\n",
    "    \"\"\"Return frequency of number of labels in the data, i.e., what percentage have 1 label, 0 labels, etc.\"\"\"\n",
    "    count_by_row = data['performance'].y.sum(dim=1)\n",
    "    n_samples = data['performance'].y.shape[0]\n",
    "    counter = Counter((int(x) for x in (count_by_row)))\n",
    "    for i in range(len(counter)):\n",
    "        count = counter[i]\n",
    "        freq = count / n_samples\n",
    "        print(f\"Num samples with {i} labels: {freq:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = HeteroData()\n",
    "\n",
    "def index_tensor(tensor):\n",
    "    \"\"\"Return 0, 1, 2... for each value in tensor. (An index.)\n",
    "\n",
    "    When sampling graph nodes, we want a direct lookup of the node\n",
    "    ids.\n",
    "    \"\"\"\n",
    "    return torch.arange(0, tensor.size(0), dtype=torch.int64).reshape(-1, 1)\n",
    "\n",
    "# This is a little clunky. The nodes are not expected to provide\n",
    "# substantial feature information--the information is the graph.\n",
    "data['performance'].x = index_tensor(create.performances())\n",
    "data['song'].x = index_tensor(create.songs())\n",
    "data['artist'].x = index_tensor(create.artists())\n",
    "\n",
    "data['artist', 'performs', 'performance'].edge_index = create.artist_performance_edges()\n",
    "data['performance', 'performing', 'song'].edge_index = create.performance_song_edges()\n",
    "data['artist', 'composed', 'song'].edge_index = create.artist_song_edges()\n",
    "\n",
    "data['performance'].y = create.labels()\n",
    "data['performance'].train_mask = create.train_mask()\n",
    "data['performance'].dev_mask = create.dev_mask()\n",
    "data['performance'].test_mask = create.test_mask()\n",
    "\n",
    "# data['artist', 'performs', 'performance'].edge_attr = <instrument>\n",
    "data = ToUndirected()(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create.label_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)\n",
    "print(\n",
    "    f\"The graph contains {'' if data.has_isolated_nodes() else 'no '}isolated nodes and\",\n",
    "    f\"is {'directed' if data.is_directed() else 'undirected'}.\"\n",
    ")\n",
    "frequency_of_n_labels(data)\n",
    "for style, count in (zip(create.label_names(), data['performance'].y.sum(dim=0))):\n",
    "    print(f\"  {style}: {int(count) / create._labels.shape[0]:.1%}\")\n",
    "    # Easy Listening is probably a mislabel by modern standards.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_degrees(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Style Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "def train_indicies(mask):\n",
    "    num_nodes = mask.shape[0]\n",
    "    all_node_indicies = torch.arange(num_nodes)\n",
    "    return all_node_indicies[mask]\n",
    "\n",
    "train_loader = NeighborLoader(\n",
    "    data,\n",
    "    [15, 15, 15],\n",
    "    batch_size=128,\n",
    "    input_nodes=('performance', train_indicies(data['performance'].train_mask)),\n",
    ")\n",
    "dev_loader = NeighborLoader(\n",
    "    data,\n",
    "    [15, 15, 15],\n",
    "    batch_size=128,\n",
    "    input_nodes=('performance', train_indicies(data['performance'].dev_mask)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNTrainingLogic:\n",
    "    \"\"\"Define training step and eval steps.\"\"\"\n",
    "    def __init__(self, model, optimizer, criterion):\n",
    "        self.device = next(model.parameters()).device\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def train_step(self, engine, batch: HeteroData) -> dict:\n",
    "        \"\"\"Complete one step of gradient descent.\"\"\"\n",
    "        self.model.train()\n",
    "        self.optimizer.zero_grad()\n",
    "        batch.to(self.device)\n",
    "        batch_size = batch['performance'].batch_size\n",
    "        y_pred = model(batch.x_dict, batch.edge_index_dict)[:batch_size]\n",
    "        y_true = batch['performance'].y[:batch_size].to(torch.float)\n",
    "        loss = self.criterion(y_pred, y_true.to(torch.float))  # TODO: need to cast here is just an artifact of wrong type in data.\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return {'loss': loss.item(), 'y_pred': y_pred.detach(), 'y_true': y_true.detach()}\n",
    "\n",
    "    def eval_step(self, engine, batch: HeteroData) -> dict:\n",
    "        \"\"\"Complete one pass over a batch of data with no-grad and return results.\"\"\"\n",
    "        self.model.eval()\n",
    "        batch.to(self.device)\n",
    "\n",
    "        batch_size = batch['performance'].batch_size\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(batch.x_dict, batch.edge_index_dict)[:batch_size]\n",
    "            y_true = batch['performance'].y[:batch_size].to(torch.float)\n",
    "            loss = self.criterion(y_pred, y_true.to(torch.float))\n",
    "        return {'y_pred': y_pred, 'y_true': y_true}\n",
    "\n",
    "model_config = {\n",
    "    'hidden_dim': 128,\n",
    "    'embed_dim': 64,\n",
    "    'dropout': 0.2\n",
    "}\n",
    "\n",
    "model = NodeClassifier(\n",
    "    JazzModel(\n",
    "        data['performance'].num_nodes,\n",
    "        data['artist'].num_nodes,\n",
    "        data['song'].num_nodes,\n",
    "        hidden_dim=model_config['hidden_dim'],\n",
    "        embed_dim=model_config['embed_dim'],\n",
    "        dropout=model_config['dropout'],\n",
    "        metadata=data.metadata()\n",
    "    ),\n",
    "    hidden_dim=model_config['hidden_dim'],\n",
    "    num_classes=len(create.label_names())\n",
    ")\n",
    "\n",
    "\n",
    "experiment_config = {\n",
    "    'model': model_config,\n",
    "    'lr': .001,\n",
    "    'batch_size': train_loader.batch_size,\n",
    "    'epochs': 15\n",
    "}\n",
    "\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=experiment_config['lr'])\n",
    "trainer_logic = GNNTrainingLogic(model, optimizer, criterion)\n",
    "# assert trainer_logic.train_step(None, batch) is not None, \"This is really just checking that the forward pass works.\"\n",
    "\n",
    "experiment_logger = JSONRunLogger(run_name='gnn_classifier_slim_data', config=experiment_config)\n",
    "\n",
    "accuracy = Accuracy(output_transform=binary_output_transform)\n",
    "\n",
    "trainer = Engine(trainer_logic.train_step)\n",
    "train_evaluator = Engine(trainer_logic.eval_step)\n",
    "dev_evaluator = Engine(trainer_logic.eval_step)\n",
    "\n",
    "metrics = {\n",
    "    'accuracy': Accuracy(output_transform=binary_output_transform),\n",
    "    'recall': Recall(output_transform=binary_output_transform),\n",
    "    'precision': Precision(output_transform=binary_output_transform),\n",
    "    'loss': Loss(criterion, output_transform=lambda out: (out['y_pred'], out['y_true']))\n",
    "}\n",
    "\n",
    "for name, metric in metrics.items():\n",
    "    metric.attach(train_evaluator, name)\n",
    "    metric.attach(dev_evaluator, name)\n",
    "\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, run_evaluator, train_evaluator, train_loader, \"Training\")\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, run_evaluator, dev_evaluator, dev_loader, \"Validation\")\n",
    "train_evaluator.add_event_handler(Events.EPOCH_COMPLETED, log_experiment, experiment_logger, 'train', trainer)\n",
    "dev_evaluator.add_event_handler(Events.EPOCH_COMPLETED, log_experiment, experiment_logger, 'dev', trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.run(train_loader, max_epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Prediction\n",
    "\n",
    "Quick shot at writing an edge prediction model. \n",
    "Conceptually, a recommender system based on this prediction \"who worked with whom, on what?\"\n",
    "Thus, it's a lot like asking Theolious Monk \"What would you recommend?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)\n",
    "performs_edge_count = data[('artist', 'performs', 'performance')].num_edges\n",
    "\n",
    "split_graph = T.RandomLinkSplit(\n",
    "    num_val=int(performs_edge_count * .1),\n",
    "    num_test=int(performs_edge_count * .1),\n",
    "    disjoint_train_ratio=.3,\n",
    "    neg_sampling_ratio=2.0,\n",
    "    add_negative_train_samples=False,\n",
    "    edge_types=('artist', 'performs', 'performance'),\n",
    "    rev_edge_types=('performance', 'rev_performs', 'artist')\n",
    ")\n",
    "train_data, dev_data, test_data = split_graph(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "def edge_training_data_factory(data: HeteroData) -> LinkNeighborLoader:\n",
    "    edge_loader = LinkNeighborLoader(\n",
    "        data=data,\n",
    "        num_neighbors=[15, 15],\n",
    "        neg_sampling_ratio=2.0,\n",
    "        edge_label_index=(('artist', 'performs', 'performance'), train_data['performs'].edge_label_index),\n",
    "        edge_label=None,\n",
    "        batch_size=128,\n",
    "        shuffle=True\n",
    "    )\n",
    "    return edge_loader\n",
    "\n",
    "edge_loader_train = edge_training_data_factory(train_data)\n",
    "edge_loader_dev = edge_training_data_factory(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    'hidden_dim': 128,\n",
    "    'embed_dim': 64,\n",
    "    'dropout': 0.\n",
    "}\n",
    "\n",
    "model = LinkPredictionModel(JazzModel(\n",
    "    data['performance'].num_nodes,\n",
    "    data['artist'].num_nodes,\n",
    "    data['song'].num_nodes,\n",
    "    hidden_dim=model_config['hidden_dim'],\n",
    "    embed_dim=model_config['embed_dim'],\n",
    "    dropout=model_config['dropout'],\n",
    "    metadata=data.metadata()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(edge_loader_train))\n",
    "batch['performs'].edge_label\n",
    "batch['performs'].edge_label\n",
    "batch['performs'].edge_label_index.shape\n",
    "model(batch.x_dict, batch.edge_index_dict, batch['performs'].edge_label_index).shape\n",
    "# batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNTrainingLogic:\n",
    "    \"\"\"Define training step and eval steps.\"\"\"\n",
    "    def __init__(self, model, optimizer, criterion):\n",
    "        self.device = next(model.parameters()).device\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def _extract_model_args(self, batch):\n",
    "        return batch.x_dict, batch.edge_index_dict, batch['performs'].edge_label_index\n",
    "\n",
    "    def train_step(self, engine, batch: HeteroData) -> dict:\n",
    "        \"\"\"Complete one step of gradient descent.\"\"\"\n",
    "        self.model.train()\n",
    "        self.optimizer.zero_grad()\n",
    "        batch.to(self.device)\n",
    "\n",
    "        y_pred = self.model(*self._extract_model_args(batch))\n",
    "        y_true = batch['performs'].edge_label\n",
    "        loss = self.criterion(y_pred, y_true)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return {'loss': loss.item(), 'y_pred': y_pred.detach(), 'y_true': y_true.detach()}\n",
    "\n",
    "    def eval_step(self, engine, batch: HeteroData) -> dict:\n",
    "        \"\"\"Complete one pass over a batch of data with no-grad and return results.\"\"\"\n",
    "        self.model.eval()\n",
    "        batch.to(self.device)\n",
    "        with torch.no_grad():\n",
    "            y_pred = self.model(*self._extract_model_args(batch))\n",
    "            y_true = batch['performs'].edge_label\n",
    "        return {'y_pred': y_pred, 'y_true': y_true}\n",
    "\n",
    "experiment_config = {\n",
    "    'model': model_config,\n",
    "    'lr': .001,\n",
    "    'batch_size': edge_loader_train.batch_size,\n",
    "    'epochs': 15\n",
    "}\n",
    "\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=experiment_config['lr'])\n",
    "trainer_logic = GNNTrainingLogic(model, optimizer, criterion)\n",
    "trainer_logic.train_step(None, batch) is not None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_logger = JSONRunLogger(run_name='gnn_slim_data', config=experiment_config)\n",
    "\n",
    "accuracy = Accuracy(output_transform=binary_output_transform)\n",
    "\n",
    "trainer = Engine(trainer_logic.train_step)\n",
    "train_evaluator = Engine(trainer_logic.eval_step)\n",
    "dev_evaluator = Engine(trainer_logic.eval_step)\n",
    "\n",
    "metrics = {\n",
    "    'accuracy': Accuracy(output_transform=binary_output_transform),\n",
    "    'recall': Recall(output_transform=binary_output_transform),\n",
    "    'precision': Precision(output_transform=binary_output_transform),\n",
    "    'loss': Loss(criterion, output_transform=lambda out: (out['y_pred'], out['y_true']))\n",
    "}\n",
    "\n",
    "for name, metric in metrics.items():\n",
    "    metric.attach(train_evaluator, name)\n",
    "    metric.attach(dev_evaluator, name)\n",
    "\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, run_evaluator, train_evaluator, edge_loader_train, \"Training\")\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, run_evaluator, dev_evaluator, edge_loader_dev, \"Validation\")\n",
    "train_evaluator.add_event_handler(Events.EPOCH_COMPLETED, log_experiment, experiment_logger, 'train', trainer)\n",
    "dev_evaluator.add_event_handler(Events.EPOCH_COMPLETED, log_experiment, experiment_logger, 'dev', trainer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.run(edge_loader_train, experiment_config['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.run(edge_loader_train, 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
