{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import Counter\n",
    "import jsonlines\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.typing import ArrayLike\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "from torch_geometric.nn import GraphConv, to_hetero, HeteroConv\n",
    "\n",
    "from jazz_graph.pyg_data.pyg_data import CreateTensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = '/workspace/local_data/graph_parquet_proto'\n",
    "create = CreateTensors(models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: report on the data a little more concreately.\n",
    "# E.g., who are the hub nodes? How many nodes have > 50 edges.\n",
    "# how many nodes have < 6 edges? All these, by type.\n",
    "# Get really fancy and visualize a sub-graph.\n",
    "\n",
    "def frequency_of_n_labels(data: HeteroData):\n",
    "    \"\"\"Return frequency of number of labels in the data, i.e., what percentage have 1 label, 0 labels, etc.\"\"\"\n",
    "    count_by_row = data['performance'].y.sum(dim=1)\n",
    "    n_samples = data['performance'].y.shape[0]\n",
    "    counter = Counter((int(x) for x in (count_by_row)))\n",
    "    for i in range(len(counter)):\n",
    "        count = counter[i]\n",
    "        freq = count / n_samples\n",
    "        print(f\"Num samples with {i} labels: {freq:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = HeteroData()\n",
    "\n",
    "def index_tensor(tensor):\n",
    "    \"\"\"Return 0, 1, 2... for each value in tensor. (An index.)\n",
    "\n",
    "    When sampling graph nodes, we want a direct lookup of the node\n",
    "    ids.\n",
    "    \"\"\"\n",
    "    return torch.arange(0, tensor.size(0), dtype=torch.int64).reshape(-1, 1)\n",
    "\n",
    "# This is a little clunky. The nodes are not expected to provide\n",
    "# substantial feature information--the information is the graph.\n",
    "data['performance'].x = index_tensor(create.performances())\n",
    "data['song'].x = index_tensor(create.songs())\n",
    "data['artist'].x = index_tensor(create.artists())\n",
    "\n",
    "data['artist', 'performs', 'performance'].edge_index = create.artist_performance_edges()\n",
    "data['performance', 'performing', 'song'].edge_index = create.performance_song_edges()\n",
    "data['artist', 'composed', 'song'].edge_index = create.artist_song_edges()\n",
    "\n",
    "data['performance'].y = create.labels()\n",
    "data['performance'].train_mask = create.train_mask()\n",
    "data['performance'].dev_mask = create.dev_mask()\n",
    "data['performance'].test_mask = create.test_mask()\n",
    "\n",
    "# data['artist', 'performs', 'performance'].edge_attr = <instrument>\n",
    "data = ToUndirected()(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)\n",
    "print(\n",
    "    f\"The graph contains {'' if data.has_isolated_nodes() else 'no '}isolated nodes and\",\n",
    "    f\"is {'directed' if data.is_directed() else 'undirected'}.\"\n",
    ")\n",
    "frequency_of_n_labels(data)\n",
    "for style, count in (zip(create._labels.columns, data['performance'].y.sum(dim=0))):\n",
    "    print(f\"  {style}: {int(count) / create._labels.shape[0]:.1%}\")\n",
    "    # Easy Listening is probably a mislabel by modern standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JazzGNN(nn.Module):\n",
    "    def __init__(self, num_performances, num_artists, num_songs, hidden_dims, embed_dims, output_dims, metadata):\n",
    "        super().__init__()\n",
    "\n",
    "        self.performance_embed = nn.Embedding(num_performances, embed_dims)\n",
    "        self.song_embed = nn.Embedding(num_songs, embed_dims)\n",
    "        self.artist_embded = nn.Embedding(num_artists, embed_dims)\n",
    "\n",
    "        self.conv1 = HeteroConv({\n",
    "            key: GraphConv(embed_dims, hidden_dims) for key in metadata[1]\n",
    "        })\n",
    "        self.conv2 = HeteroConv({\n",
    "            key: GraphConv(hidden_dims, hidden_dims) for key in metadata[1]\n",
    "        })\n",
    "        self.conv3 = HeteroConv({\n",
    "            key: GraphConv(hidden_dims, hidden_dims) for key in metadata[1]\n",
    "        })\n",
    "\n",
    "        self.classifier = nn.Linear(hidden_dims, output_dims)\n",
    "\n",
    "    def forward(self, x_dict, edge_dict) -> torch.Tensor:\n",
    "        x_embedded = {\n",
    "            'performance': self.performance_embed(x_dict['performance'].view(-1)),\n",
    "            'artist': self.artist_embded(x_dict['artist'].view(-1)),\n",
    "            'song': self.song_embed(x_dict['song'].view(-1))\n",
    "        }\n",
    "\n",
    "        x = self.conv1(x_embedded, edge_dict)\n",
    "        x = {key: F.relu(val) for key, val in x.items()}\n",
    "        x = self.conv2(x, edge_dict)\n",
    "        x = {key: F.relu(val) for key, val in x.items()}\n",
    "        x = self.conv3(x, edge_dict)\n",
    "\n",
    "        logits = self.classifier(x['performance'])\n",
    "        return logits\n",
    "\n",
    "model = JazzGNN(\n",
    "    data['performance'].num_nodes,\n",
    "    data['artist'].num_nodes,\n",
    "    data['song'].num_nodes,\n",
    "    hidden_dims=128,\n",
    "    embed_dims=64,\n",
    "    output_dims=20,\n",
    "    metadata=data.metadata()\n",
    ")\n",
    "\n",
    "data['performance'].num_nodes\n",
    "data['artist'].num_nodes\n",
    "\n",
    "model.performance_embed.weight.shape\n",
    "model.artist_embded.weight.shape\n",
    "model.song_embed.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['performance'].y\n",
    "model(data.x_dict, data.edge_index_dict)\n",
    "# data.x_dict['performance'].view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
